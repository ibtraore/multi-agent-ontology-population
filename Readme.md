# A Multi LLM-based Agents for Modular Ontology Population: A Case Study on ADHD Ontology

This is the repository for ICTAI 2025 submission for `A Multi LLM-based Agents for Modular Ontology Population: A Case Study on ADHD Ontology`.
This approach to automatically populate a modular ontology using multi LLM-based agents from unstructured documents.
Given a modular ontology and a set of documents, the task is to extract instance from the documents
while complying to the given ontology (concepts, relations, domain/range constraints).

**Note:** Due to the confidentiality of medical data, all personal patient information has been replaced with fictitious data.

## ADHD Semantic Model

<img width="1258" alt="music3" src="https://github.com/ibtraore/multi-agent-ontology-population/blob/main/ADHD_Semantic_Model.jpeg?raw=true">

## The proposed Multi-Agent System

<img width="1258" alt="music3" src="https://github.com/ibtraore/multi-agent-ontology-population/blob/main/Multi_agents_approach.jpg?raw=true">

## Repo content
The structure of the repo is as the following.

- [Data](Data) : Contains the source documents used for ontology population. This includes medical diagnostic reports in PDF format and activity schedules in JSON format.
- [Multi_Agents](Multi_Agents) :  Contains the outputs and evaluation results of our multi-agent system.
    - [Profile Crew](Multi_Agents/Profile_Crew) :Stores the outputs generated by the agent team responsible for extracting data from the Profile module. Organized by the three use cases, each subfolder includes the outputs for the three tested models: DeepSeek, Mistral, and LLama.
    - [Module Crew](Multi_Agents/Module_Crew/) : Stores the outputs generated by the agent team responsible for extracting data from the other ontology modules. Similarly, the results are organized by the three use cases and include outputs for DeepSeek, Mistral, and LLama.
    - [Aggregated output](Multi_Agents/Aggregated_output/) : Contains the merged outputs from both agent teams, representing the complete set of extracted RDF triples. This folder also includes the corresponding ground truth data for each use case.
    - [Evaluation](Multi_Agents/Evaluation/) : Contains the evaluation results comparing the extracted triples to the ground truth, organized by use case and model.
    - [Pydantic_Types](Multi_Agents/Pydantic_Types): contains the Pydantic models for the seven modules. These types are used to guide the agents in generating instances and triples that comply with the ontology schema.
- [Single_LLM](Single_LLM) : Contains the outputs and evaluation results of the state-of-the-art single LLM-based approach.
    - [Generated_triples](Single_LLM/Generated_triples) : Includes the RDF triples generated by the single LLM in response to input prompts.
    - [Evaluation_results](Single_LLM/Evaluation_results) : Stores the evaluation results assessing the accuracy, conformity, and hallucination rates of the triples generated by the single LLM.
    - [`CaseX_situation_description.txt`](Single_LLM/Case1_situation_description.txt) : This file provides a narrative description of a specific situation involving the child. It is generated by combining contextual information from the childâ€™s activity schedule (timetable) and relevant positive signs extracted from the diagnostic report.
    - [`CaseX_situation_prompt.json`](Single_LLM/Case1_situation_prompt.json) : This file contains the prompt used in the single LLM configuration. It merges the situation description with the ontology modules and includes an example of expected triple extraction to guide the model.
- [Ontology](Ontology) : The modualr ontology used in this studie.
    - `Person` : This module includes personal details (e.g., name, gender, birthdate) and information about individuals present during an activity, which helps contextualize the situation.
    - `Activity` : This module captures the patient's ongoing activities, critical for interpreting behavior.
    - `Environnement` : This module identifies the spatial context (learning, living, social, or play settings).
    - `Challenge` : This module lists difficulties commonly reported by caregivers or teachers, including academic, social, emotional, or environmental issues.
    - `Time` : This module defines temporal context using instants and intervals (with start and end times).
    - `Situation` : This module categorizes events requiring contextualization and links them to related elements across modules through defined properties and relationships.
    - `Profile` : This module models the patient's health status using diagnostic form data, such as ADHD type, symptoms, and comorbidities.

## Evaluation : cosinus similarity
To evaluate the similarity between the triples generated by the agents and the ground truth, we used the sentence-transformers model `all-MiniLM-L6-v2` ([paper](https://arxiv.org/abs/2002.10957)) as embedding model. Based on the generated embeddings, we then computed the cosine similarity, using a fixed threshold of 0.8.

## Illustrations from the Experimentation Phase
This section presents a selection of screenshots from the experiments we conducted. These images illustrate key steps and outputs of the system, providing a visual overview of the implementation and results.

- This screenshot shows the web interface used to upload PDF and JSON documents, which initiates the instance extraction process using our multi-agent approach.
<img width="1258" alt="music3" src="https://github.com/ibtraore/multi-agent-ontology-population/blob/main/Experimentation_Screenshots/Processing_Screenshot.png?raw=true">

- The second screenshot presents the interface for visualizing extraction results, allowing users to inspect the output produced by the agents.
<img width="1258" alt="music3" src="https://github.com/ibtraore/multi-agent-ontology-population/blob/main/Experimentation_Screenshots/Outputs_Screenshot.png?raw=true">
 

